{"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"name":"python","version":"3.10.12","mimetype":"text/x-python","codemirror_mode":{"name":"ipython","version":3},"pygments_lexer":"ipython3","nbconvert_exporter":"python","file_extension":".py"}},"nbformat_minor":4,"nbformat":4,"cells":[{"cell_type":"markdown","source":"# **Importing libraries**","metadata":{}},{"cell_type":"code","source":"#model\nimport tensorflow as tf\nfrom sklearn.model_selection import train_test_split\n\n#nlp processing\nimport unicodedata\nimport re\nimport numpy as np\n\n\nimport warnings \nwarnings.filterwarnings('ignore')\n","metadata":{"execution":{"iopub.status.busy":"2023-09-26T20:48:30.221501Z","iopub.execute_input":"2023-09-26T20:48:30.221885Z","iopub.status.idle":"2023-09-26T20:48:45.810830Z","shell.execute_reply.started":"2023-09-26T20:48:30.221856Z","shell.execute_reply":"2023-09-26T20:48:45.809723Z"},"trusted":true},"execution_count":2,"outputs":[{"name":"stderr","text":"/opt/conda/lib/python3.10/site-packages/scipy/__init__.py:146: UserWarning: A NumPy version >=1.16.5 and <1.23.0 is required for this version of SciPy (detected version 1.23.5\n  warnings.warn(f\"A NumPy version >={np_minversion} and <{np_maxversion}\"\n","output_type":"stream"}]},{"cell_type":"markdown","source":"# **Data preprocessing**\n**The basic text processing in NLP are:**\n1. Sentence Segmentation\n2. Normalization\n3. Tokenization","metadata":{}},{"cell_type":"markdown","source":"## **Segmentation** \nformatting data to be in a question answer format","metadata":{}},{"cell_type":"code","source":"#reading data\ndata=open('/kaggle/input/simple-dialogs-for-chatbot/dialogs.txt','r').read()","metadata":{"execution":{"iopub.status.busy":"2023-09-26T20:48:45.813164Z","iopub.execute_input":"2023-09-26T20:48:45.813882Z","iopub.status.idle":"2023-09-26T20:48:45.835121Z","shell.execute_reply.started":"2023-09-26T20:48:45.813846Z","shell.execute_reply":"2023-09-26T20:48:45.834217Z"},"trusted":true},"execution_count":3,"outputs":[]},{"cell_type":"code","source":"#paried list of question and corresponding answer\nQA_list=[QA.split('\\t') for QA in data.split('\\n')]\nprint(QA_list[:5])","metadata":{"execution":{"iopub.status.busy":"2023-09-26T20:48:45.837429Z","iopub.execute_input":"2023-09-26T20:48:45.838087Z","iopub.status.idle":"2023-09-26T20:48:45.846725Z","shell.execute_reply.started":"2023-09-26T20:48:45.838054Z","shell.execute_reply":"2023-09-26T20:48:45.845686Z"},"trusted":true},"execution_count":4,"outputs":[{"name":"stdout","text":"[['hi, how are you doing?', \"i'm fine. how about yourself?\"], [\"i'm fine. how about yourself?\", \"i'm pretty good. thanks for asking.\"], [\"i'm pretty good. thanks for asking.\", 'no problem. so how have you been?'], ['no problem. so how have you been?', \"i've been great. what about you?\"], [\"i've been great. what about you?\", \"i've been good. i'm in school right now.\"]]\n","output_type":"stream"}]},{"cell_type":"code","source":"questions=[row[0] for row in QA_list]\nanswers=[row[1] for row in QA_list]","metadata":{"execution":{"iopub.status.busy":"2023-09-26T20:48:45.849483Z","iopub.execute_input":"2023-09-26T20:48:45.849836Z","iopub.status.idle":"2023-09-26T20:48:45.862222Z","shell.execute_reply.started":"2023-09-26T20:48:45.849805Z","shell.execute_reply":"2023-09-26T20:48:45.861095Z"},"trusted":true},"execution_count":5,"outputs":[]},{"cell_type":"code","source":"print(questions[0:5])\nprint(answers[0:5])","metadata":{"execution":{"iopub.status.busy":"2023-09-26T20:48:45.863656Z","iopub.execute_input":"2023-09-26T20:48:45.864203Z","iopub.status.idle":"2023-09-26T20:48:45.878904Z","shell.execute_reply.started":"2023-09-26T20:48:45.864172Z","shell.execute_reply":"2023-09-26T20:48:45.877872Z"},"trusted":true},"execution_count":6,"outputs":[{"name":"stdout","text":"['hi, how are you doing?', \"i'm fine. how about yourself?\", \"i'm pretty good. thanks for asking.\", 'no problem. so how have you been?', \"i've been great. what about you?\"]\n[\"i'm fine. how about yourself?\", \"i'm pretty good. thanks for asking.\", 'no problem. so how have you been?', \"i've been great. what about you?\", \"i've been good. i'm in school right now.\"]\n","output_type":"stream"}]},{"cell_type":"markdown","source":"## **Normalization**\nTo reduce its randomness, bringing it closer to a predefined “standard”","metadata":{}},{"cell_type":"code","source":"def remove_diacritic(text):\n    return ''.join(char for char in unicodedata.normalize('NFD',text)\n                  if unicodedata.category(char) !='Mn')","metadata":{"execution":{"iopub.status.busy":"2023-09-26T20:48:45.880322Z","iopub.execute_input":"2023-09-26T20:48:45.881152Z","iopub.status.idle":"2023-09-26T20:48:45.891554Z","shell.execute_reply.started":"2023-09-26T20:48:45.881127Z","shell.execute_reply":"2023-09-26T20:48:45.890716Z"},"trusted":true},"execution_count":7,"outputs":[]},{"cell_type":"code","source":"def preprocessing(text):\n    \n    #Case folding and removing extra whitespaces\n    text=remove_diacritic(text.lower().strip())\n    \n    #Ensuring punctuation marks to be treated as tokens\n    text=re.sub(r\"([?.!,¿])\", r\" \\1 \", text)\n    \n    #Removing redundant spaces\n    text= re.sub(r'[\" \"]+', \" \", text)\n    \n    #Removing non alphabetic characters\n    text=re.sub(r\"[^a-zA-Z?.!,¿]+\", \" \", text)\n    \n    text=text.strip()\n    \n    #Indicating the start and end of each sentence\n    text='<start> ' + text + ' <end>'\n    \n    return text","metadata":{"execution":{"iopub.status.busy":"2023-09-26T21:06:41.681652Z","iopub.execute_input":"2023-09-26T21:06:41.682034Z","iopub.status.idle":"2023-09-26T21:06:41.688797Z","shell.execute_reply.started":"2023-09-26T21:06:41.682005Z","shell.execute_reply":"2023-09-26T21:06:41.687554Z"},"trusted":true},"execution_count":53,"outputs":[]},{"cell_type":"code","source":"preprocessed_questions=[preprocessing(sen) for sen in questions]\npreprocessed_answers=[preprocessing(sen) for sen in answers]\n\nprint(preprocessed_questions[0])\nprint(preprocessed_answers[0])","metadata":{"execution":{"iopub.status.busy":"2023-09-26T21:06:43.531632Z","iopub.execute_input":"2023-09-26T21:06:43.531999Z","iopub.status.idle":"2023-09-26T21:06:43.750227Z","shell.execute_reply.started":"2023-09-26T21:06:43.531969Z","shell.execute_reply":"2023-09-26T21:06:43.748582Z"},"trusted":true},"execution_count":54,"outputs":[{"name":"stdout","text":"<start> hi , how are you doing ? <end>\n<start> i m fine . how about yourself ? <end>\n","output_type":"stream"}]},{"cell_type":"markdown","source":"## **Tokenization**","metadata":{}},{"cell_type":"code","source":"def tokenize(lang):\n    lang_tokenizer = tf.keras.preprocessing.text.Tokenizer(\n      filters='')\n    \n    #build vocabulary on unique words \n    lang_tokenizer.fit_on_texts(lang)\n    \n    return lang_tokenizer","metadata":{"execution":{"iopub.status.busy":"2023-09-26T21:06:47.927469Z","iopub.execute_input":"2023-09-26T21:06:47.927901Z","iopub.status.idle":"2023-09-26T21:06:47.934183Z","shell.execute_reply.started":"2023-09-26T21:06:47.927870Z","shell.execute_reply":"2023-09-26T21:06:47.933074Z"},"trusted":true},"execution_count":55,"outputs":[]},{"cell_type":"markdown","source":"## **Word Embedding**\nrepresenting words in form of real-valued vetors","metadata":{}},{"cell_type":"code","source":"def vectorization(lang_tokenizer,lang):\n    \n    #word embedding for training the neural network\n    tensor = lang_tokenizer.texts_to_sequences(lang)\n\n    tensor = tf.keras.preprocessing.sequence.pad_sequences(tensor,\n                                                         padding='post')\n\n    return tensor","metadata":{"execution":{"iopub.status.busy":"2023-09-26T21:06:50.528344Z","iopub.execute_input":"2023-09-26T21:06:50.529040Z","iopub.status.idle":"2023-09-26T21:06:50.535398Z","shell.execute_reply.started":"2023-09-26T21:06:50.529008Z","shell.execute_reply":"2023-09-26T21:06:50.534267Z"},"trusted":true},"execution_count":56,"outputs":[]},{"cell_type":"markdown","source":"## **Creating Dataset** \nfor training and testing the model","metadata":{}},{"cell_type":"code","source":"def load_Dataset(data,size=None):\n    \n    if(size!=None):\n        y,X=data[:size]\n    else:\n        y,X=data\n        \n    X_tokenizer=tokenize(X)\n    y_tokenizer=tokenize(y)\n    \n    X_tensor=vectorization(X_tokenizer,X)\n    y_tensor=vectorization(y_tokenizer,y)\n    \n    return  X_tensor,X_tokenizer, y_tensor, y_tokenizer","metadata":{"execution":{"iopub.status.busy":"2023-09-26T21:06:53.072262Z","iopub.execute_input":"2023-09-26T21:06:53.072663Z","iopub.status.idle":"2023-09-26T21:06:53.081342Z","shell.execute_reply.started":"2023-09-26T21:06:53.072632Z","shell.execute_reply":"2023-09-26T21:06:53.080198Z"},"trusted":true},"execution_count":57,"outputs":[]},{"cell_type":"code","source":"size=30000\ndata=preprocessed_answers,preprocessed_questions\\\n\nX_tensor,X_tokenizer, y_tensor, y_tokenizer=load_Dataset(data,size)","metadata":{"execution":{"iopub.status.busy":"2023-09-26T21:06:55.537327Z","iopub.execute_input":"2023-09-26T21:06:55.537713Z","iopub.status.idle":"2023-09-26T21:06:55.741015Z","shell.execute_reply.started":"2023-09-26T21:06:55.537681Z","shell.execute_reply":"2023-09-26T21:06:55.740086Z"},"trusted":true},"execution_count":58,"outputs":[]},{"cell_type":"code","source":"# Calculate max_length of the target tensors\nmax_length_y, max_length_X = y_tensor.shape[1], X_tensor.shape[1]","metadata":{"execution":{"iopub.status.busy":"2023-09-26T21:06:56.640255Z","iopub.execute_input":"2023-09-26T21:06:56.640652Z","iopub.status.idle":"2023-09-26T21:06:56.645752Z","shell.execute_reply.started":"2023-09-26T21:06:56.640622Z","shell.execute_reply":"2023-09-26T21:06:56.644562Z"},"trusted":true},"execution_count":59,"outputs":[]},{"cell_type":"markdown","source":"## **Splitting Data**\nCreating training and validation sets using an 80-20 split after the required preprocessing is applied to the whole data\n","metadata":{}},{"cell_type":"code","source":"X_train, X_val, y_train, y_val = train_test_split(X_tensor, y_tensor, test_size=0.2)\n\n# Show length\nprint(len(X_train), len(y_train), len(X_val), len(y_val))","metadata":{"execution":{"iopub.status.busy":"2023-09-26T21:07:01.555951Z","iopub.execute_input":"2023-09-26T21:07:01.556314Z","iopub.status.idle":"2023-09-26T21:07:01.564127Z","shell.execute_reply.started":"2023-09-26T21:07:01.556285Z","shell.execute_reply":"2023-09-26T21:07:01.562987Z"},"trusted":true},"execution_count":60,"outputs":[{"name":"stdout","text":"2980 2980 745 745\n","output_type":"stream"}]},{"cell_type":"markdown","source":"## **Tensorflow Dataset**","metadata":{}},{"cell_type":"code","source":"BUFFER_SIZE = len(X_train)\nBATCH_SIZE = 64\nsteps_per_epoch = len(X_train)//BATCH_SIZE\nembedding_dim = 256\nunits = 1024\nvocab_inp_size = len(X_tokenizer.word_index)+1\nvocab_tar_size = len(y_tokenizer.word_index)+1\n\ndataset = tf.data.Dataset.from_tensor_slices((X_train, y_train)).shuffle(BUFFER_SIZE)\ndataset = dataset.batch(BATCH_SIZE, drop_remainder=True)\n\nexample_input_batch, example_target_batch = next(iter(dataset))\nexample_input_batch.shape, example_target_batch.shape","metadata":{"execution":{"iopub.status.busy":"2023-09-26T21:07:03.816314Z","iopub.execute_input":"2023-09-26T21:07:03.817216Z","iopub.status.idle":"2023-09-26T21:07:03.850466Z","shell.execute_reply.started":"2023-09-26T21:07:03.817187Z","shell.execute_reply":"2023-09-26T21:07:03.849577Z"},"trusted":true},"execution_count":61,"outputs":[{"execution_count":61,"output_type":"execute_result","data":{"text/plain":"(TensorShape([64, 24]), TensorShape([64, 24]))"},"metadata":{}}]},{"cell_type":"markdown","source":"# **Model**\n\n**Bahdanau Attention Mechanism**\n\nhttps://machinelearningmastery.com/the-bahdanau-attention-mechanism/\n\n![bahdanau_1-229x300.png](attachment:0a8d20c3-0725-4562-a235-2281628dc65b.png)","metadata":{},"attachments":{"0a8d20c3-0725-4562-a235-2281628dc65b.png":{"image/png":"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"}}},{"cell_type":"markdown","source":"Adding attention mechanism to an Encoder-Decoder Model to make the model focus on specific parts of input sequence by assigning weights to different parts of the input sequence \n","metadata":{}},{"cell_type":"markdown","source":"## **Buliding Model Architecture** ","metadata":{}},{"cell_type":"markdown","source":"#### **Encoder**","metadata":{}},{"cell_type":"code","source":"class Encoder(tf.keras.Model):\n    def __init__(self, vocab_size, embedding_dim, enc_units, batch_sz):\n        super(Encoder, self).__init__()\n        self.batch_sz = batch_sz\n        self.enc_units = enc_units\n        self.embedding = tf.keras.layers.Embedding(vocab_size, embedding_dim)\n        self.gru = tf.keras.layers.GRU(self.enc_units,\n                                       return_sequences=True,\n                                       return_state=True,\n                                       recurrent_initializer='glorot_uniform')\n\n    def call(self, x, hidden):\n        x = self.embedding(x)\n        output, state = self.gru(x, initial_state = hidden)\n        return output, state\n\n    def initialize_hidden_state(self):\n        return tf.zeros((self.batch_sz, self.enc_units))","metadata":{"execution":{"iopub.status.busy":"2023-09-26T20:48:53.041070Z","iopub.execute_input":"2023-09-26T20:48:53.042064Z","iopub.status.idle":"2023-09-26T20:48:53.049917Z","shell.execute_reply.started":"2023-09-26T20:48:53.042010Z","shell.execute_reply":"2023-09-26T20:48:53.048663Z"},"trusted":true},"execution_count":17,"outputs":[]},{"cell_type":"code","source":"encoder = Encoder(vocab_inp_size, embedding_dim, units, BATCH_SIZE)\n\n# sample input\nsample_hidden = encoder.initialize_hidden_state()\nsample_output, sample_hidden = encoder(example_input_batch, sample_hidden)\nprint ('Encoder output shape: (batch size, sequence length, units) {}'.format(sample_output.shape))\nprint ('Encoder Hidden state shape: (batch size, units) {}'.format(sample_hidden.shape))","metadata":{"execution":{"iopub.status.busy":"2023-09-26T20:48:53.051753Z","iopub.execute_input":"2023-09-26T20:48:53.052151Z","iopub.status.idle":"2023-09-26T20:48:58.235479Z","shell.execute_reply.started":"2023-09-26T20:48:53.052121Z","shell.execute_reply":"2023-09-26T20:48:58.234238Z"},"trusted":true},"execution_count":18,"outputs":[{"name":"stdout","text":"Encoder output shape: (batch size, sequence length, units) (64, 24, 1024)\nEncoder Hidden state shape: (batch size, units) (64, 1024)\n","output_type":"stream"}]},{"cell_type":"markdown","source":"#### **Attention Mechanism**","metadata":{}},{"cell_type":"code","source":"class BahdanauAttention(tf.keras.layers.Layer):\n    def __init__(self, units):\n        super(BahdanauAttention, self).__init__()\n        self.W1 = tf.keras.layers.Dense(units)\n        self.W2 = tf.keras.layers.Dense(units)\n        self.V = tf.keras.layers.Dense(1)\n\n    def call(self, query, values):\n        # query hidden state shape == (batch_size, hidden size)\n        # query_with_time_axis shape == (batch_size, 1, hidden size)\n        # values shape == (batch_size, max_len, hidden size)\n        # we are doing this to broadcast addition along the time axis to calculate the score\n        query_with_time_axis = tf.expand_dims(query, 1)\n\n        # score shape == (batch_size, max_length, 1)\n        # we get 1 at the last axis because we are applying score to self.V\n        # the shape of the tensor before applying self.V is (batch_size, max_length, units)\n        score = self.V(tf.nn.tanh(\n            self.W1(query_with_time_axis) + self.W2(values)))\n\n        # attention_weights shape == (batch_size, max_length, 1)\n        attention_weights = tf.nn.softmax(score, axis=1)\n\n        # context_vector shape after sum == (batch_size, hidden_size)\n        context_vector = attention_weights * values\n        context_vector = tf.reduce_sum(context_vector, axis=1)\n\n        return context_vector, attention_weights","metadata":{"execution":{"iopub.status.busy":"2023-09-26T20:48:58.237207Z","iopub.execute_input":"2023-09-26T20:48:58.237925Z","iopub.status.idle":"2023-09-26T20:48:58.246780Z","shell.execute_reply.started":"2023-09-26T20:48:58.237889Z","shell.execute_reply":"2023-09-26T20:48:58.245853Z"},"trusted":true},"execution_count":19,"outputs":[]},{"cell_type":"code","source":"attention_layer = BahdanauAttention(10)\nattention_result, attention_weights = attention_layer(sample_hidden, sample_output)\n\nprint(\"Attention result shape: (batch size, units) {}\".format(attention_result.shape))\nprint(\"Attention weights shape: (batch_size, sequence_length, 1) {}\".format(attention_weights.shape))","metadata":{"execution":{"iopub.status.busy":"2023-09-26T20:48:58.248049Z","iopub.execute_input":"2023-09-26T20:48:58.248470Z","iopub.status.idle":"2023-09-26T20:48:58.382339Z","shell.execute_reply.started":"2023-09-26T20:48:58.248435Z","shell.execute_reply":"2023-09-26T20:48:58.381370Z"},"trusted":true},"execution_count":20,"outputs":[{"name":"stdout","text":"Attention result shape: (batch size, units) (64, 1024)\nAttention weights shape: (batch_size, sequence_length, 1) (64, 24, 1)\n","output_type":"stream"}]},{"cell_type":"markdown","source":"#### **Decoder** ","metadata":{}},{"cell_type":"code","source":"class Decoder(tf.keras.Model):\n    def __init__(self, vocab_size, embedding_dim, dec_units, batch_sz):\n        super(Decoder, self).__init__()\n        self.batch_sz = batch_sz\n        self.dec_units = dec_units\n        self.embedding = tf.keras.layers.Embedding(vocab_size, embedding_dim)\n        self.gru = tf.keras.layers.GRU(self.dec_units,\n                                       return_sequences=True,\n                                       return_state=True,\n                                       recurrent_initializer='glorot_uniform')\n        self.fc = tf.keras.layers.Dense(vocab_size)\n\n        # used for attention\n        self.attention = BahdanauAttention(self.dec_units)\n\n    def call(self, x, hidden, enc_output):\n        # enc_output shape == (batch_size, max_length, hidden_size)\n        context_vector, attention_weights = self.attention(hidden, enc_output)\n\n        # x shape after passing through embedding == (batch_size, 1, embedding_dim)\n        x = self.embedding(x)\n\n        # x shape after concatenation == (batch_size, 1, embedding_dim + hidden_size)\n        x = tf.concat([tf.expand_dims(context_vector, 1), x], axis=-1)\n\n        # passing the concatenated vector to the GRU\n        output, state = self.gru(x)\n\n        # output shape == (batch_size * 1, hidden_size)\n        output = tf.reshape(output, (-1, output.shape[2]))\n\n        # output shape == (batch_size, vocab)\n        x = self.fc(output)\n\n        return x, state, attention_weights","metadata":{"execution":{"iopub.status.busy":"2023-09-26T20:48:58.383656Z","iopub.execute_input":"2023-09-26T20:48:58.384473Z","iopub.status.idle":"2023-09-26T20:48:58.393957Z","shell.execute_reply.started":"2023-09-26T20:48:58.384430Z","shell.execute_reply":"2023-09-26T20:48:58.393107Z"},"trusted":true},"execution_count":21,"outputs":[]},{"cell_type":"code","source":"decoder = Decoder(vocab_tar_size, embedding_dim, units, BATCH_SIZE)\n\nsample_decoder_output, _, _ = decoder(tf.random.uniform((BATCH_SIZE, 1)),\n                                      sample_hidden, sample_output)\n\nprint ('Decoder output shape: (batch_size, vocab size) {}'.format(sample_decoder_output.shape))","metadata":{"execution":{"iopub.status.busy":"2023-09-26T20:48:58.395397Z","iopub.execute_input":"2023-09-26T20:48:58.395843Z","iopub.status.idle":"2023-09-26T20:48:58.498379Z","shell.execute_reply.started":"2023-09-26T20:48:58.395813Z","shell.execute_reply":"2023-09-26T20:48:58.497567Z"},"trusted":true},"execution_count":22,"outputs":[{"name":"stdout","text":"Decoder output shape: (batch_size, vocab size) (64, 2356)\n","output_type":"stream"}]},{"cell_type":"markdown","source":"## **Training Model**","metadata":{}},{"cell_type":"markdown","source":"1. Pass the input through the encoder which return encoder output and the encoder hidden state.\n2. The encoder output, encoder hidden state and the decoder input (which is the start token) is passed to the decoder.\n3. The decoder returns the predictions and the decoder hidden state.\n4. The decoder hidden state is then passed back into the model and the predictions are used to calculate the loss.\n5. Use teacher forcing to decide the next input to the decoder.\n6. Teacher forcing is the technique where the target word is passed as the next input to the decoder.\n7. The final step is to calculate the gradients and apply it to the optimizer and backpropagate.","metadata":{}},{"cell_type":"code","source":"optimizer = tf.keras.optimizers.Adam()\nloss_object = tf.keras.losses.SparseCategoricalCrossentropy(\n    from_logits=True, reduction='none')\n\ndef loss_function(real, pred):\n    mask = tf.math.logical_not(tf.math.equal(real, 0))\n    loss_ = loss_object(real, pred)\n\n    mask = tf.cast(mask, dtype=loss_.dtype)\n    loss_ *= mask\n\n    return tf.reduce_mean(loss_)","metadata":{"execution":{"iopub.status.busy":"2023-09-26T20:48:58.499923Z","iopub.execute_input":"2023-09-26T20:48:58.500236Z","iopub.status.idle":"2023-09-26T20:48:58.510173Z","shell.execute_reply.started":"2023-09-26T20:48:58.500206Z","shell.execute_reply":"2023-09-26T20:48:58.509263Z"},"trusted":true},"execution_count":23,"outputs":[]},{"cell_type":"code","source":"@tf.function\ndef train_step(inp, targ, enc_hidden):\n    loss = 0\n\n    with tf.GradientTape() as tape:\n        enc_output, enc_hidden = encoder(inp, enc_hidden)\n\n        dec_hidden = enc_hidden\n\n        dec_input = tf.expand_dims([y_tokenizer.word_index['<start>']] * BATCH_SIZE, 1)\n\n        # Teacher forcing - feeding the target as the next input\n        for t in range(1, targ.shape[1]):\n            # passing enc_output to the decoder\n            predictions, dec_hidden, _ = decoder(dec_input, dec_hidden, enc_output)\n\n            loss += loss_function(targ[:, t], predictions)\n\n            # using teacher forcing\n            dec_input = tf.expand_dims(targ[:, t], 1)\n\n    batch_loss = (loss / int(targ.shape[1]))\n\n    variables = encoder.trainable_variables + decoder.trainable_variables\n\n    gradients = tape.gradient(loss, variables)\n\n    optimizer.apply_gradients(zip(gradients, variables))\n\n    return batch_loss","metadata":{"execution":{"iopub.status.busy":"2023-09-26T20:48:58.511304Z","iopub.execute_input":"2023-09-26T20:48:58.511644Z","iopub.status.idle":"2023-09-26T20:48:58.526710Z","shell.execute_reply.started":"2023-09-26T20:48:58.511614Z","shell.execute_reply":"2023-09-26T20:48:58.525828Z"},"trusted":true},"execution_count":24,"outputs":[]},{"cell_type":"code","source":"EPOCHS = 40\n\nfor epoch in range(1, EPOCHS + 1):\n    enc_hidden = encoder.initialize_hidden_state()\n    total_loss = 0\n\n    for (batch, (inp, targ)) in enumerate(dataset.take(steps_per_epoch)):\n        batch_loss = train_step(inp, targ, enc_hidden)\n        total_loss += batch_loss\n\n    if(epoch % 4 == 0):\n        print('Epoch:{:3d} Loss:{:.4f}'.format(epoch,\n                                          total_loss / steps_per_epoch))","metadata":{"execution":{"iopub.status.busy":"2023-09-26T20:50:20.791318Z","iopub.execute_input":"2023-09-26T20:50:20.791716Z","iopub.status.idle":"2023-09-26T20:56:25.753934Z","shell.execute_reply.started":"2023-09-26T20:50:20.791684Z","shell.execute_reply":"2023-09-26T20:56:25.752784Z"},"trusted":true},"execution_count":26,"outputs":[{"name":"stdout","text":"Epoch:  4 Loss:1.5256\nEpoch:  8 Loss:1.2739\nEpoch: 12 Loss:1.1026\nEpoch: 16 Loss:0.9474\nEpoch: 20 Loss:0.7886\nEpoch: 24 Loss:0.6198\nEpoch: 28 Loss:0.4336\nEpoch: 32 Loss:0.2459\nEpoch: 36 Loss:0.1113\nEpoch: 40 Loss:0.0499\n","output_type":"stream"}]},{"cell_type":"markdown","source":"## **Model Evaluation**","metadata":{}},{"cell_type":"code","source":"def remove_tags(sentence):\n    return sentence.split(\"<start>\")[-1].split(\"<end>\")[0]","metadata":{"execution":{"iopub.status.busy":"2023-09-26T21:07:08.828749Z","iopub.execute_input":"2023-09-26T21:07:08.829199Z","iopub.status.idle":"2023-09-26T21:07:08.834858Z","shell.execute_reply.started":"2023-09-26T21:07:08.829162Z","shell.execute_reply":"2023-09-26T21:07:08.833782Z"},"trusted":true},"execution_count":62,"outputs":[]},{"cell_type":"code","source":"def evaluate(sentence):\n    sentence = preprocessing(sentence)\n\n    inputs = [X_tokenizer.word_index[i] for i in sentence.split(' ')]\n    inputs = tf.keras.preprocessing.sequence.pad_sequences([inputs],\n                                                         maxlen=max_length_X,\n                                                         padding='post')\n    inputs = tf.convert_to_tensor(inputs)\n\n    result = ''\n\n    hidden = [tf.zeros((1, units))]\n    enc_out, enc_hidden = encoder(inputs, hidden)\n\n    dec_hidden = enc_hidden\n    dec_input = tf.expand_dims([y_tokenizer.word_index['<start>']], 0)\n\n    for t in range(max_length_y):\n        predictions, dec_hidden, attention_weights = decoder(dec_input,\n                                                             dec_hidden,\n                                                             enc_out)\n\n        # storing the attention weights to plot later on\n        attention_weights = tf.reshape(attention_weights, (-1, ))\n\n        predicted_id = tf.argmax(predictions[0]).numpy()\n\n        result += y_tokenizer.index_word[predicted_id] + ' '\n\n        if y_tokenizer.index_word[predicted_id] == '<end>':\n            return remove_tags(result), remove_tags(sentence)\n\n        # the predicted ID is fed back into the model\n        dec_input = tf.expand_dims([predicted_id], 0)\n\n    return remove_tags(result), remove_tags(sentence)","metadata":{"execution":{"iopub.status.busy":"2023-09-26T21:07:11.443906Z","iopub.execute_input":"2023-09-26T21:07:11.444268Z","iopub.status.idle":"2023-09-26T21:07:11.454341Z","shell.execute_reply.started":"2023-09-26T21:07:11.444238Z","shell.execute_reply":"2023-09-26T21:07:11.453380Z"},"trusted":true},"execution_count":63,"outputs":[]},{"cell_type":"code","source":"def ask(sentence):\n    result, sentence = evaluate(sentence)\n\n    print('Question: %s' % (sentence))\n    print('Predicted answer: {}'.format(result))","metadata":{"execution":{"iopub.status.busy":"2023-09-26T21:07:11.790660Z","iopub.execute_input":"2023-09-26T21:07:11.791427Z","iopub.status.idle":"2023-09-26T21:07:11.796816Z","shell.execute_reply.started":"2023-09-26T21:07:11.791389Z","shell.execute_reply":"2023-09-26T21:07:11.795847Z"},"trusted":true},"execution_count":64,"outputs":[]},{"cell_type":"code","source":"ask(questions[1])","metadata":{"execution":{"iopub.status.busy":"2023-09-26T21:09:00.638669Z","iopub.execute_input":"2023-09-26T21:09:00.639079Z","iopub.status.idle":"2023-09-26T21:09:00.755920Z","shell.execute_reply.started":"2023-09-26T21:09:00.639048Z","shell.execute_reply":"2023-09-26T21:09:00.753979Z"},"trusted":true},"execution_count":70,"outputs":[{"name":"stdout","text":"Question:  i m fine . how about yourself ? \nPredicted answer: that probably good life okay . \n","output_type":"stream"}]}]}